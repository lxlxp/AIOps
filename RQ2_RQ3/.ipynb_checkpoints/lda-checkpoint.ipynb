{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38160/653894832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwordnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhrases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocess'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import preprocess as pre\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models import CoherenceModel\n",
    "from preprocess import processbody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n",
      "send data datadog use go collect data use go want \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "dataset = \"datadog\"\n",
    "df = pd.read_csv('../dataset/{}-aiops.csv'.format(dataset))\n",
    "docs = []\n",
    "df['clean_text'] = ''\n",
    "for index, row in df.iterrows():\n",
    "    title = processbody(row['title'])\n",
    "    body = processbody(row['body'])\n",
    "    s = (title+\" \"+body).strip()\n",
    "    df.at[index, 'clean_text'] = docs.append(s)\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0][:50])\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "docs = [[token for token in doc if len(token) <= 15] for doc in docs]\n",
    "np.save('{}_docs.npy'.format(dataset), np.array(docs))\n",
    "# docs = [doc for doc in docs if len(doc)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1379\n",
      "Number of documents: 456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "dictionary.filter_extremes(no_below=2)\n",
    "dictionary.save('{}.dict'.format(dataset))\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "np.save('{}_corpus.npy'.format(dataset),np.array(corpus))\n",
    "# corpus = np.load('./data/dl2.npy', allow_pickle=True).tolist()\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "elastic_lda = LdaModel.load('elastic_8.model')\n",
    "elastic_lda.print_topics(num_topics=num_topics, num_words=15)\n",
    "dictionary = Dictionary.load('elastic.dict')\n",
    "corpus = np.load('elastic_corpus.npy', allow_pickle=True).tolist()\n",
    "docs = np.load('elastic_docs.npy', allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310, 295, 347, 376, 226, 630, 96, 105]\n"
     ]
    }
   ],
   "source": [
    "doc_topics = []\n",
    "for doc in elastic_lda.get_document_topics(corpus):\n",
    "    doc_topic = []\n",
    "    topics = []\n",
    "    for topic in doc:\n",
    "        doc_topic.append(topic[1])\n",
    "        topics.append(topic[0])\n",
    "    # doc_topic_max.append(doc_topic.index(max(doc_topic)))\n",
    "    doc_topics.append(topics[doc_topic.index(max(doc_topic))])\n",
    "    # print(doc_topics)\n",
    "\n",
    "\n",
    "topics = []\n",
    "for i in range(num_topics):\n",
    "    topics.append(0)\n",
    "for topic in doc_topics:\n",
    "    topics[topic] += 1\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>...</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>hot_score</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>258503</td>\n",
       "      <td>43718919</td>\n",
       "      <td>Stackdriver vs ELK for app engine</td>\n",
       "      <td>&lt;p&gt;Im a little confused about this because the...</td>\n",
       "      <td>43722994.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-5-1 12:11:39</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1028270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>google-app-engine|elasticsearch|elastic-stack|gcp</td>\n",
       "      <td>3736</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>258504</td>\n",
       "      <td>43754002</td>\n",
       "      <td>Extracting a substring after a match position ...</td>\n",
       "      <td>&lt;p&gt;Objective : I have a log file from where I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-5-3 07:39:31</td>\n",
       "      <td>...</td>\n",
       "      <td>3830161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3830161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>regex|logstash|elastic-stack|logstash-grok</td>\n",
       "      <td>2792</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>258505</td>\n",
       "      <td>43756763</td>\n",
       "      <td>How to write grok pattern in logstash</td>\n",
       "      <td>&lt;p&gt;I am trying to start with logstash and my a...</td>\n",
       "      <td>43763303.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-5-3 09:55:11</td>\n",
       "      <td>...</td>\n",
       "      <td>1919092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1919092.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>elasticsearch|logstash|elastic-stack|logstash-...</td>\n",
       "      <td>1391</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258506</td>\n",
       "      <td>43776044</td>\n",
       "      <td>Logstash 'Cannot load an invalid configuration'</td>\n",
       "      <td>&lt;p&gt;I am trying to configure logstash for the f...</td>\n",
       "      <td>43781561.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-5-4 07:03:31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2519577.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nginx|logstash|elastic-stack|logstash-grok</td>\n",
       "      <td>195</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>258507</td>\n",
       "      <td>43781240</td>\n",
       "      <td>How to send PHP app logs directly to ELK service?</td>\n",
       "      <td>&lt;p&gt;According to the &lt;a href=\"https://docs.deve...</td>\n",
       "      <td>43782311.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-5-4 11:10:35</td>\n",
       "      <td>...</td>\n",
       "      <td>4716084.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4716084.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>elastic-stack|monolog|swisscomdev</td>\n",
       "      <td>7702</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id   post_id  \\\n",
       "0           0  258503  43718919   \n",
       "1           1  258504  43754002   \n",
       "2           2  258505  43756763   \n",
       "3           3  258506  43776044   \n",
       "4           4  258507  43781240   \n",
       "\n",
       "                                               title  \\\n",
       "0                  Stackdriver vs ELK for app engine   \n",
       "1  Extracting a substring after a match position ...   \n",
       "2              How to write grok pattern in logstash   \n",
       "3    Logstash 'Cannot load an invalid configuration'   \n",
       "4  How to send PHP app logs directly to ELK service?   \n",
       "\n",
       "                                                body  accepted_answer_id  \\\n",
       "0  <p>Im a little confused about this because the...          43722994.0   \n",
       "1  <p>Objective : I have a log file from where I ...                 NaN   \n",
       "2  <p>I am trying to start with logstash and my a...          43763303.0   \n",
       "3  <p>I am trying to configure logstash for the f...          43781561.0   \n",
       "4  <p>According to the <a href=\"https://docs.deve...          43782311.0   \n",
       "\n",
       "   answer_count  comment_count  community_owned_date      creation_date  ...  \\\n",
       "0             1              2                   NaN  2017-5-1 12:11:39  ...   \n",
       "1             1              0                   NaN  2017-5-3 07:39:31  ...   \n",
       "2             1              0                   NaN  2017-5-3 09:55:11  ...   \n",
       "3             2              0                   NaN  2017-5-4 07:03:31  ...   \n",
       "4             1              0                   NaN  2017-5-4 11:10:35  ...   \n",
       "\n",
       "   last_editor_user_id owner_display_name owner_user_id parent_id  \\\n",
       "0                  NaN                NaN     1028270.0       NaN   \n",
       "1            3830161.0                NaN     3830161.0       NaN   \n",
       "2            1919092.0                NaN     1919092.0       NaN   \n",
       "3                  NaN                NaN     2519577.0       NaN   \n",
       "4            4716084.0                NaN     4716084.0       NaN   \n",
       "\n",
       "   post_type_id score                                               tags  \\\n",
       "0             1     6  google-app-engine|elasticsearch|elastic-stack|gcp   \n",
       "1             1     1         regex|logstash|elastic-stack|logstash-grok   \n",
       "2             1     0  elasticsearch|logstash|elastic-stack|logstash-...   \n",
       "3             1     0         nginx|logstash|elastic-stack|logstash-grok   \n",
       "4             1     1                  elastic-stack|monolog|swisscomdev   \n",
       "\n",
       "   view_count  hot_score  topic  \n",
       "0        3736         19      0  \n",
       "1        2792         13      3  \n",
       "2        1391         13      5  \n",
       "3         195         10      5  \n",
       "4        7702         17      5  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/elastic-aiops.csv\")\n",
    "df['topic'] = 100\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'topic'] = doc_topics[i]\n",
    "    i += 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2385\n"
     ]
    }
   ],
   "source": [
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phase0 = df[df['topic']==4]\n",
    "phase1 = df[(df['topic']==5) | (df['topic']==7)]\n",
    "phase2 = df[(df['topic']==0) | (df['topic']==1) | (df['topic']==2) | (df['topic']==3)]\n",
    "phase3 = df[df['topic']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "735\n",
      "1328\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(phase0))\n",
    "print(len(phase1))\n",
    "print(len(phase2))\n",
    "print(len(phase3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phase0_popularity = phase0[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "phase0col_mean = phase0_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "phase1_popularity = phase1[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "phase1col_mean = phase1_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "phase2_popularity = phase2[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "phase2col_mean = phase2_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "phase3_popularity = phase3[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "phase3col_mean = phase3_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "popularity = pd.concat([phase0col_mean, phase1col_mean, phase2col_mean, phase3col_mean], axis=1)\n",
    "#统计受欢迎程度\n",
    "# popularity.to_csv(\"{}-popularity.csv\".format(\"elastic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 0.8878834187049376), ('2', 0.5405700636216926), ('0', 0.43588998502365933), ('3', 0.20866943191859097)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mcdm\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(popularity.T)\n",
    "scaled_features = scaler.transform(popularity.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=[\"view_count\", \"answer_count\", \"comment_count\",\"favorite_count\", \"score\"])\n",
    "popularityrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "print(popularityrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000986\n",
       "1    0.001038\n",
       "2    0.001325\n",
       "3    0.001547\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty1 = popularity.iloc[1]/popularity.iloc[0]\n",
    "difficulty1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cnt0 = 0\n",
    "for index, row in phase0.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt0 += 1\n",
    "cnt1 = 0\n",
    "for index, row in phase1.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt1 += 1\n",
    "cnt2 = 0\n",
    "for index, row in phase2.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt2 += 1\n",
    "cnt3 = 0\n",
    "for index, row in phase3.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt3 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69469027 0.65170068 0.62349398 0.75      ]\n"
     ]
    }
   ],
   "source": [
    "unanswered = np.array([cnt0, cnt1, cnt2, cnt3], dtype=float)\n",
    "sum = np.array([len(phase0), len(phase1), len(phase2), len(phase3)], dtype=float)\n",
    "w_o = unanswered/sum\n",
    "print(w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w/o</th>\n",
       "      <td>0.694690</td>\n",
       "      <td>0.651701</td>\n",
       "      <td>0.623494</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "pd   0.000986  0.001038  0.001325  0.001547\n",
       "w/o  0.694690  0.651701  0.623494  0.750000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [difficulty1.values, w_o]\n",
    "difficulty = pd.DataFrame(data=data, index=['pd', 'w/o'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "difficulty[[\"0\", \"1\", \"2\", \"3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "连接上了...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pymysql\n",
    "#连接数据库\n",
    "def connectDB():\n",
    "    # 打开数据库连接\n",
    "    db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"Wangnima258\", database=\"aiops\")\n",
    "    print(\"连接上了...\")\n",
    "    return db\n",
    "#查询操作\n",
    "def queryDb(db, sql):\n",
    "    # 使用 cursor() 方法创建一个游标对象 cursor\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有记录列表\n",
    "    results = cursor.fetchone()\n",
    "    return results\n",
    "\n",
    "db = connectDB()\n",
    "cnt0 = 0\n",
    "span0 = 0\n",
    "for index, row in phase0.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span0 += span\n",
    "        cnt0 += 1\n",
    "hours0 = span0/cnt0\n",
    "\n",
    "cnt1 = 0\n",
    "span1 = 0\n",
    "for index, row in phase1.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span1 += span\n",
    "        cnt1 += 1\n",
    "hours1 = span1/cnt1\n",
    "\n",
    "cnt2 = 0\n",
    "span2 = 0\n",
    "for index, row in phase2.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span2 += span\n",
    "        cnt2 += 1\n",
    "hours2 = span2/cnt2\n",
    "\n",
    "cnt3 = 0\n",
    "span3 = 0\n",
    "for index, row in phase3.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span3 += span\n",
    "        cnt3 += 1\n",
    "hours3 = span3/cnt3\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hours = np.array([hours0, hours1, hours2, hours3], dtype=float)\n",
    "data = [difficulty1.values, w_o, hours]\n",
    "difficulty = pd.DataFrame(data=data, index=['pd', 'w/o', 'days'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "# difficulty.to_csv(\"elastic-difficulty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 1.0),\n",
       " ('1', 0.3914897168566913),\n",
       " ('2', 0.388433005915791),\n",
       " ('0', 0.38541356677429167)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(difficulty.T)\n",
    "scaled_features = scaler.transform(difficulty.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=['pd', 'w/o', 'days'])\n",
    "difficultyrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "difficultyrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "D:\\anaconda3\\envs\\Torch\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "stage0month = phase0[['post_id','creation_date']]\n",
    "stage0month['creation_date'] = pd.to_datetime(stage0month['creation_date'])\n",
    "stage0month = stage0month.set_index('creation_date')\n",
    "stage0month = stage0month.resample('M').count().to_period('M')\n",
    "stage0month.rename(columns={'post_id':'0'},inplace = True)\n",
    "stage0month['sum'] = stage0month['0'].cumsum()\n",
    "\n",
    "stage1month = phase1[['post_id','creation_date']]\n",
    "stage1month['creation_date'] = pd.to_datetime(stage1month['creation_date'])\n",
    "stage1month = stage1month.set_index('creation_date')\n",
    "stage1month = stage1month.resample('M').count().to_period('M')\n",
    "stage1month.rename(columns={'post_id':'1'},inplace = True)\n",
    "stage1month['sum'] = stage1month['1'].cumsum()\n",
    "\n",
    "stage2month = phase2[['post_id','creation_date']]\n",
    "stage2month['creation_date'] = pd.to_datetime(stage2month['creation_date'])\n",
    "stage2month = stage2month.set_index('creation_date')\n",
    "stage2month = stage2month.resample('M').count().to_period('M')\n",
    "stage2month.rename(columns={'post_id':'2'},inplace = True)\n",
    "stage2month['sum'] = stage2month['2'].cumsum()\n",
    "\n",
    "stage3month = phase3[['post_id','creation_date']]\n",
    "stage3month['creation_date'] = pd.to_datetime(stage3month['creation_date'])\n",
    "stage3month = stage3month.set_index('creation_date')\n",
    "stage3month = stage3month.resample('M').count().to_period('M')\n",
    "stage3month.rename(columns={'post_id':'3'},inplace = True)\n",
    "stage3month['sum'] = stage3month['3'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>...</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>hot_score</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>258456</td>\n",
       "      <td>49059485</td>\n",
       "      <td>format splunk query by renaming search elements</td>\n",
       "      <td>&lt;p&gt;I could use a little help with a splunk que...</td>\n",
       "      <td>49060727.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-3-1 22:09:57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017466.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>splunk</td>\n",
       "      <td>180</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>258457</td>\n",
       "      <td>49077872</td>\n",
       "      <td>POST a query to Splunk REST API /search/jobs/ ...</td>\n",
       "      <td>&lt;p&gt;I would like to send a search/query to Splu...</td>\n",
       "      <td>49078427.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-3-2 21:45:34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4109882.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rest|go|splunk</td>\n",
       "      <td>1605</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>258458</td>\n",
       "      <td>49080092</td>\n",
       "      <td>How do I retain table fields in Splunk after a...</td>\n",
       "      <td>&lt;p&gt;I've got a search where basically I want to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-3-3 02:41:18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7507925.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>charts|splunk|splunk-query</td>\n",
       "      <td>295</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>258459</td>\n",
       "      <td>49091472</td>\n",
       "      <td>Forwarding syslog messages from raspbian to sp...</td>\n",
       "      <td>&lt;p&gt;how can i configure my raspberry pi having ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-3-4 02:52:04</td>\n",
       "      <td>...</td>\n",
       "      <td>4420967.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9440219.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>raspbian|splunk</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>258460</td>\n",
       "      <td>49111651</td>\n",
       "      <td>How to produce rows for non-existing time buck...</td>\n",
       "      <td>&lt;p&gt;I have produced a table like this:&lt;/p&gt;\\n\\n&lt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-3-5 13:32:58</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5184632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>splunk|splunk-query|splunk-formula</td>\n",
       "      <td>1164</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id   post_id  \\\n",
       "0           0  258456  49059485   \n",
       "1           1  258457  49077872   \n",
       "2           2  258458  49080092   \n",
       "3           3  258459  49091472   \n",
       "4           4  258460  49111651   \n",
       "\n",
       "                                               title  \\\n",
       "0    format splunk query by renaming search elements   \n",
       "1  POST a query to Splunk REST API /search/jobs/ ...   \n",
       "2  How do I retain table fields in Splunk after a...   \n",
       "3  Forwarding syslog messages from raspbian to sp...   \n",
       "4  How to produce rows for non-existing time buck...   \n",
       "\n",
       "                                                body  accepted_answer_id  \\\n",
       "0  <p>I could use a little help with a splunk que...          49060727.0   \n",
       "1  <p>I would like to send a search/query to Splu...          49078427.0   \n",
       "2  <p>I've got a search where basically I want to...                 NaN   \n",
       "3  <p>how can i configure my raspberry pi having ...                 NaN   \n",
       "4  <p>I have produced a table like this:</p>\\n\\n<...                 NaN   \n",
       "\n",
       "   answer_count  comment_count  community_owned_date      creation_date  ...  \\\n",
       "0             1              0                   NaN  2018-3-1 22:09:57  ...   \n",
       "1             1              0                   NaN  2018-3-2 21:45:34  ...   \n",
       "2             1              0                   NaN  2018-3-3 02:41:18  ...   \n",
       "3             1              0                   NaN  2018-3-4 02:52:04  ...   \n",
       "4             2              0                   NaN  2018-3-5 13:32:58  ...   \n",
       "\n",
       "   last_editor_user_id owner_display_name owner_user_id parent_id  \\\n",
       "0                  NaN                NaN     1017466.0       NaN   \n",
       "1                  NaN                NaN     4109882.0       NaN   \n",
       "2                  NaN                NaN     7507925.0       NaN   \n",
       "3            4420967.0                NaN     9440219.0       NaN   \n",
       "4                  NaN                NaN     5184632.0       NaN   \n",
       "\n",
       "   post_type_id score                                tags  view_count  \\\n",
       "0             1     0                              splunk         180   \n",
       "1             1     0                      rest|go|splunk        1605   \n",
       "2             1     0          charts|splunk|splunk-query         295   \n",
       "3             1    -1                     raspbian|splunk         149   \n",
       "4             1     0  splunk|splunk-query|splunk-formula        1164   \n",
       "\n",
       "   hot_score  topic  \n",
       "0         10      5  \n",
       "1         13      5  \n",
       "2          9      7  \n",
       "3          8      6  \n",
       "4         13      8  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splunkdf = pd.read_csv(\"../dataset/splunk-aiops.csv\")\n",
    "splunkdf['topic'] = 100\n",
    "i = 0\n",
    "for index, row in splunkdf.iterrows():\n",
    "    splunkdf.at[index, 'topic'] = doc_topics[i]\n",
    "    i += 1\n",
    "splunkdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7    312\n",
       "8    217\n",
       "2    130\n",
       "1    125\n",
       "5    108\n",
       "3    103\n",
       "0     74\n",
       "6     72\n",
       "4     16\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(splunkdf))\n",
    "splunkdf['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "splunkphase0 = splunkdf[(splunkdf['topic']==4) | (splunkdf['topic']==2)]\n",
    "splunkphase1 = splunkdf[(splunkdf['topic']==0) | (splunkdf['topic']==6)]\n",
    "splunkphase2 = splunkdf[(splunkdf['topic']==3) | (splunkdf['topic']==5) | (splunkdf['topic']==7) | (splunkdf['topic']==8)]\n",
    "splunkphase3 = splunkdf[splunkdf['topic']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "146\n",
      "740\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "print(len(splunkphase0))\n",
    "print(len(splunkphase1))\n",
    "print(len(splunkphase2))\n",
    "print(len(splunkphase3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "splunkphase0_popularity = splunkphase0[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "splunkphase0col_mean = splunkphase0_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "splunkphase1_popularity = splunkphase1[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "splunkphase1col_mean = splunkphase1_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "splunkphase2_popularity = splunkphase2[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "splunkphase2col_mean = splunkphase2_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "splunkphase3_popularity = splunkphase3[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "splunkphase3col_mean = splunkphase3_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "splunkpopularity = pd.concat([splunkphase0col_mean, splunkphase1col_mean, splunkphase2col_mean, splunkphase3col_mean], axis=1)\n",
    "#统计受欢迎程度\n",
    "# splunkpopularity.to_csv(\"{}-popularity.csv\".format(\"splunk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 0.5943046524771858),\n",
       " ('2', 0.5923001848673584),\n",
       " ('0', 0.4984430693557657),\n",
       " ('3', 0.0)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mcdm\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(splunkpopularity.T)\n",
    "scaled_features = scaler.transform(splunkpopularity.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=[\"view_count\", \"answer_count\", \"comment_count\",\"favorite_count\", \"score\"])\n",
    "splunkpopularityrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "splunkpopularityrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.002113\n",
       "1    0.001592\n",
       "2    0.002033\n",
       "3    0.002515\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splunkdifficulty1 = splunkpopularity.iloc[1]/splunkpopularity.iloc[0]\n",
    "splunkdifficulty1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cnt0 = 0\n",
    "for index, row in splunkphase0.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt0 += 1\n",
    "cnt1 = 0\n",
    "for index, row in splunkphase1.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt1 += 1\n",
    "cnt2 = 0\n",
    "for index, row in splunkphase2.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt2 += 1\n",
    "cnt3 = 0\n",
    "for index, row in splunkphase3.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt3 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73972603 0.67123288 0.61891892 0.72      ]\n"
     ]
    }
   ],
   "source": [
    "unanswered = np.array([cnt0, cnt1, cnt2, cnt3], dtype=float)\n",
    "sum = np.array([len(splunkphase0), len(splunkphase1), len(splunkphase2), len(splunkphase3)], dtype=float)\n",
    "w_o = unanswered/sum\n",
    "print(w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w/o</th>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.618919</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "pd   0.002113  0.001592  0.002033  0.002515\n",
       "w/o  0.739726  0.671233  0.618919  0.720000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [splunkdifficulty1.values, w_o]\n",
    "splunkdifficulty = pd.DataFrame(data=data, index=['pd', 'w/o'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "splunkdifficulty[[\"0\", \"1\", \"2\", \"3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "连接上了...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pymysql\n",
    "#连接数据库\n",
    "def connectDB():\n",
    "    # 打开数据库连接\n",
    "    db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"Wangnima258\", database=\"aiops\")\n",
    "    print(\"连接上了...\")\n",
    "    return db\n",
    "#查询操作\n",
    "def queryDb(db, sql):\n",
    "    # 使用 cursor() 方法创建一个游标对象 cursor\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有记录列表\n",
    "    results = cursor.fetchone()\n",
    "    return results\n",
    "\n",
    "db = connectDB()\n",
    "cnt0 = 0\n",
    "span0 = 0\n",
    "for index, row in splunkphase0.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span0 += span\n",
    "        cnt0 += 1\n",
    "hours0 = span0/cnt0\n",
    "\n",
    "cnt1 = 0\n",
    "span1 = 0\n",
    "for index, row in splunkphase1.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span1 += span\n",
    "        cnt1 += 1\n",
    "hours1 = span1/cnt1\n",
    "\n",
    "cnt2 = 0\n",
    "span2 = 0\n",
    "for index, row in splunkphase2.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span2 += span\n",
    "        cnt2 += 1\n",
    "hours2 = span2/cnt2\n",
    "\n",
    "cnt3 = 0\n",
    "span3 = 0\n",
    "for index, row in splunkphase3.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span3 += span\n",
    "        cnt3 += 1\n",
    "hours3 = span3/cnt3\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hours = np.array([hours0, hours1, hours2, hours3], dtype=float)\n",
    "data = [splunkdifficulty1.values, w_o, hours]\n",
    "splunkdifficulty = pd.DataFrame(data=data, index=['pd', 'w/o', 'days'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "# splunkdifficulty.to_csv(\"splunk-difficulty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 0.5732508815532178),\n",
       " ('1', 0.5322346980504812),\n",
       " ('0', 0.5152182755995682),\n",
       " ('2', 0.24586587112299604)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(splunkdifficulty.T)\n",
    "scaled_features = scaler.transform(splunkdifficulty.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=['pd', 'w/o', 'days'])\n",
    "splunkdifficultyrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "splunkdifficultyrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.041*\"tag\" + 0.041*\"metric\" + 0.026*\"query\" + 0.015*\"like\" + 0.015*\"value\" + 0.013*\"want\" + 0.012*\"name\" + 0.011*\"trace\" + 0.010*\"way\" + 0.010*\"custom\"'),\n",
       " (1,\n",
       "  '0.060*\"log\" + 0.029*\"file\" + 0.018*\"agent\" + 0.014*\"run\" + 0.012*\"try\" + 0.012*\"container\" + 0.012*\"app\" + 0.011*\"json\" + 0.009*\"service\" + 0.009*\"config\"'),\n",
       " (2,\n",
       "  '0.038*\"log\" + 0.018*\"monitor\" + 0.018*\"message\" + 0.016*\"create\" + 0.015*\"metric\" + 0.014*\"get\" + 0.012*\"value\" + 0.012*\"find\" + 0.011*\"dashboard\" + 0.010*\"alert\"'),\n",
       " (3,\n",
       "  '0.021*\"event\" + 0.019*\"log\" + 0.019*\"metric\" + 0.017*\"error\" + 0.017*\"time\" + 0.014*\"test\" + 0.013*\"send\" + 0.011*\"run\" + 0.011*\"try\" + 0.009*\"monitor\"'),\n",
       " (4,\n",
       "  '0.024*\"log\" + 0.017*\"error\" + 0.014*\"work\" + 0.013*\"file\" + 0.012*\"run\" + 0.011*\"try\" + 0.010*\"docker\" + 0.010*\"image\" + 0.009*\"code\" + 0.009*\"json\"'),\n",
       " (5,\n",
       "  '0.017*\"send\" + 0.016*\"metric\" + 0.014*\"log\" + 0.013*\"see\" + 0.012*\"possible\" + 0.011*\"event\" + 0.011*\"json\" + 0.010*\"agent\" + 0.010*\"server\" + 0.010*\"want\"'),\n",
       " (6,\n",
       "  '0.032*\"metric\" + 0.025*\"monitor\" + 0.022*\"alert\" + 0.016*\"query\" + 0.014*\"create\" + 0.013*\"try\" + 0.013*\"time\" + 0.013*\"like\" + 0.012*\"get\" + 0.010*\"value\"'),\n",
       " (7,\n",
       "  '0.038*\"metric\" + 0.028*\"agent\" + 0.021*\"cluster\" + 0.019*\"get\" + 0.018*\"run\" + 0.018*\"kubernetes\" + 0.015*\"application\" + 0.014*\"pod\" + 0.013*\"container\" + 0.011*\"see\"')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = 8\n",
    "datadog_lda = LdaModel.load('datadog_8.model')\n",
    "dictionary = Dictionary.load('datadog.dict')\n",
    "corpus = np.load('datadog_corpus.npy', allow_pickle=True).tolist()\n",
    "docs = np.load('datadog_docs.npy', allow_pickle=True).tolist()\n",
    "\n",
    "datadog_lda.print_topics(num_topics=num_topics, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 69, 63, 48, 37, 48, 62, 57]\n"
     ]
    }
   ],
   "source": [
    "doc_topics = []\n",
    "for doc in datadog_lda.get_document_topics(corpus):\n",
    "    doc_topic = []\n",
    "    topics = []\n",
    "    for topic in doc:\n",
    "        doc_topic.append(topic[1])\n",
    "        topics.append(topic[0])\n",
    "    # doc_topic_max.append(doc_topic.index(max(doc_topic)))\n",
    "    doc_topics.append(topics[doc_topic.index(max(doc_topic))])\n",
    "    # print(doc_topics)\n",
    "\n",
    "\n",
    "topics = []\n",
    "for i in range(num_topics):\n",
    "    topics.append(0)\n",
    "for topic in doc_topics:\n",
    "    topics[topic] += 1\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>community_owned_date</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>last_editor_display_name</th>\n",
       "      <th>last_editor_user_id</th>\n",
       "      <th>owner_display_name</th>\n",
       "      <th>owner_user_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_type_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51124961</td>\n",
       "      <td>Send data to Datadog using Go</td>\n",
       "      <td>&lt;p&gt;i'm collect data using Go and want to visua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-7-1 16:13:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9699047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>go|datadog</td>\n",
       "      <td>3637</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51323878</td>\n",
       "      <td>Datadog: PostgreSQL custom_metrics returns a s...</td>\n",
       "      <td>&lt;p&gt;I wanted to create a graph in Datadog to di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-7-13 11:15:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9763778.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>postgresql|datadog</td>\n",
       "      <td>538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>51341426</td>\n",
       "      <td>DataDog logging image reporting errors in dock...</td>\n",
       "      <td>&lt;p&gt;Using datadog docker image, with the follow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-7-14 16:43:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1414721.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>docker|logging|docker-compose|filesystems|datadog</td>\n",
       "      <td>956</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>51363915</td>\n",
       "      <td>use data-dog for testing a web app</td>\n",
       "      <td>&lt;p&gt;I am using webdriver-io to test a web-app, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-7-16 14:16:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5912110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5912110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>testing|webdriver-io|datadog</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51377442</td>\n",
       "      <td>Manually insert metrics to Datadog</td>\n",
       "      <td>&lt;p&gt;I have file full of metrics:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-7-17 09:11:26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2446102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>statsd|datadog</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   post_id                                              title  \\\n",
       "0           0  51124961                      Send data to Datadog using Go   \n",
       "1           1  51323878  Datadog: PostgreSQL custom_metrics returns a s...   \n",
       "2           2  51341426  DataDog logging image reporting errors in dock...   \n",
       "3           3  51363915                 use data-dog for testing a web app   \n",
       "4           4  51377442                 Manually insert metrics to Datadog   \n",
       "\n",
       "                                                body  accepted_answer_id  \\\n",
       "0  <p>i'm collect data using Go and want to visua...                 NaN   \n",
       "1  <p>I wanted to create a graph in Datadog to di...                 NaN   \n",
       "2  <p>Using datadog docker image, with the follow...                 NaN   \n",
       "3  <p>I am using webdriver-io to test a web-app, ...                 NaN   \n",
       "4  <p>I have file full of metrics:</p>\\n\\n<pre><c...                 NaN   \n",
       "\n",
       "   answer_count  comment_count  community_owned_date       creation_date  \\\n",
       "0             2              2                   NaN   2018-7-1 16:13:48   \n",
       "1             1              0                   NaN  2018-7-13 11:15:48   \n",
       "2             0              2                   NaN  2018-7-14 16:43:41   \n",
       "3             0              1                   NaN  2018-7-16 14:16:00   \n",
       "4             1              0                   NaN  2018-7-17 09:11:26   \n",
       "\n",
       "   favorite_count  ... last_editor_display_name last_editor_user_id  \\\n",
       "0             1.0  ...                      NaN                 NaN   \n",
       "1             NaN  ...                      NaN                 NaN   \n",
       "2             NaN  ...                      NaN                 NaN   \n",
       "3             NaN  ...                      NaN           5912110.0   \n",
       "4             0.0  ...                      NaN                 NaN   \n",
       "\n",
       "   owner_display_name  owner_user_id parent_id  post_type_id  score  \\\n",
       "0                 NaN      9699047.0       NaN             1      2   \n",
       "1                 NaN      9763778.0       NaN             1      1   \n",
       "2                 NaN      1414721.0       NaN             1      1   \n",
       "3                 NaN      5912110.0       NaN             1      1   \n",
       "4                 NaN      2446102.0       NaN             1      0   \n",
       "\n",
       "                                                tags  view_count topic  \n",
       "0                                         go|datadog        3637     4  \n",
       "1                                 postgresql|datadog         538     0  \n",
       "2  docker|logging|docker-compose|filesystems|datadog         956     4  \n",
       "3                       testing|webdriver-io|datadog          54     5  \n",
       "4                                     statsd|datadog         151     5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadogdf = pd.read_csv(\"../dataset/datadog-aiops.csv\")\n",
    "datadogdf['topic'] = 100\n",
    "i = 0\n",
    "for index, row in datadogdf.iterrows():\n",
    "    datadogdf.at[index, 'topic'] = doc_topics[i]\n",
    "    i += 1\n",
    "datadogdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    72\n",
       "1    69\n",
       "2    63\n",
       "6    62\n",
       "7    57\n",
       "5    48\n",
       "3    48\n",
       "4    37\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datadogdf))\n",
    "datadogdf['topic'].value_counts()\n",
    "# datadogdf.to_csv(\"../dataset/datadog-aiops.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadogphase0 = datadogdf[datadogdf['topic']==4]\n",
    "datadogphase1 = datadogdf[(datadogdf['topic']==1) | (datadogdf['topic']==3) | (datadogdf['topic']==5) | (datadogdf['topic']==7)]\n",
    "datadogphase2 = datadogdf[(datadogdf['topic']==0)]\n",
    "datadogphase3 = datadogdf[datadogdf['topic']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "222\n",
      "72\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(datadogphase0))\n",
    "print(len(datadogphase1))\n",
    "print(len(datadogphase2))\n",
    "print(len(datadogphase3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadogphase0_popularity = datadogphase0[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "datadogphase0col_mean = datadogphase0_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "datadogphase1_popularity = datadogphase1[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "datadogphase1col_mean = datadogphase1_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "datadogphase2_popularity = datadogphase2[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "datadogphase2col_mean = datadogphase2_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()\n",
    "\n",
    "datadogphase3_popularity = datadogphase3[['post_id','creation_date','view_count','answer_count','comment_count','favorite_count','score']]\n",
    "datadogphase3col_mean = datadogphase3_popularity[['view_count','answer_count','comment_count','favorite_count','score']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadogpopularity = pd.concat([datadogphase0col_mean, datadogphase1col_mean, datadogphase2col_mean, datadogphase3col_mean], axis=1)\n",
    "#统计受欢迎程度\n",
    "datadogpopularity.to_csv(\"{}-popularity.csv\".format(\"datadog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 0.7161450230380225),\n",
       " ('1', 0.6405423240140876),\n",
       " ('2', 0.4534866147350454),\n",
       " ('3', 0.3000149451988753)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mcdm\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(datadogpopularity.T)\n",
    "scaled_features = scaler.transform(datadogpopularity.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=[\"view_count\", \"answer_count\", \"comment_count\",\"favorite_count\", \"score\"])\n",
    "datadogpopularityrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "datadogpopularityrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.001503\n",
       "1    0.001553\n",
       "2    0.001301\n",
       "3    0.002669\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadogdifficulty1 = datadogpopularity.iloc[1]/datadogpopularity.iloc[0]\n",
    "datadogdifficulty1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cnt0 = 0\n",
    "for index, row in datadogphase0.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt0 += 1\n",
    "cnt1 = 0\n",
    "for index, row in datadogphase1.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt1 += 1\n",
    "cnt2 = 0\n",
    "for index, row in datadogphase2.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt2 += 1\n",
    "cnt3 = 0\n",
    "for index, row in datadogphase3.iterrows():\n",
    "    if np.isnan(row['accepted_answer_id']):\n",
    "        cnt3 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56756757 0.75675676 0.77777778 0.83870968]\n"
     ]
    }
   ],
   "source": [
    "unanswered = np.array([cnt0, cnt1, cnt2, cnt3], dtype=float)\n",
    "sum = np.array([len(datadogphase0), len(datadogphase1), len(datadogphase2), len(datadogphase3)], dtype=float)\n",
    "w_o = unanswered/sum\n",
    "print(w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd</th>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.002669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w/o</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "pd   0.001503  0.001553  0.001301  0.002669\n",
       "w/o  0.567568  0.756757  0.777778  0.838710"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [datadogdifficulty1.values, w_o]\n",
    "datadogdifficulty = pd.DataFrame(data=data, index=['pd', 'w/o'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "datadogdifficulty[[\"0\", \"1\", \"2\", \"3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "连接上了...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pymysql\n",
    "#连接数据库\n",
    "def connectDB():\n",
    "    # 打开数据库连接\n",
    "    db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"Wangnima258\", database=\"aiops\")\n",
    "    print(\"连接上了...\")\n",
    "    return db\n",
    "#查询操作\n",
    "def queryDb(db, sql):\n",
    "    # 使用 cursor() 方法创建一个游标对象 cursor\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    # 获取所有记录列表\n",
    "    results = cursor.fetchone()\n",
    "    return results\n",
    "db = connectDB()\n",
    "cnt0 = 0\n",
    "span0 = 0\n",
    "for index, row in datadogphase0.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span0 += span\n",
    "        cnt0 += 1\n",
    "hours0 = span0/cnt0\n",
    "\n",
    "cnt1 = 0\n",
    "span1 = 0\n",
    "for index, row in datadogphase1.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span1 += span\n",
    "        cnt1 += 1\n",
    "hours1 = span1/cnt1\n",
    "\n",
    "cnt2 = 0\n",
    "span2 = 0\n",
    "for index, row in datadogphase2.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span2 += span\n",
    "        cnt2 += 1\n",
    "hours2 = span2/cnt2\n",
    "\n",
    "cnt3 = 0\n",
    "span3 = 0\n",
    "for index, row in datadogphase3.iterrows():\n",
    "    if not np.isnan(row['accepted_answer_id']):\n",
    "        # print(row['CreationDate'])\n",
    "        start = time.mktime(time.strptime(row['creation_date'], '%Y-%m-%d %H:%M:%S'))\n",
    "        Aid = str(row['accepted_answer_id'])\n",
    "        sql = \"select creation_date from answers where post_id = \" + Aid\n",
    "        result = queryDb(db, sql)\n",
    "        if(result is None):\n",
    "            continue\n",
    "        # print(answer.iloc[0]['CreationDate'])\n",
    "        end = time.mktime(time.strptime(str(result[0]), '%Y-%m-%d %H:%M:%S'))\n",
    "        # days\n",
    "        span = round(end - start) / (3600*24)\n",
    "        span3 += span\n",
    "        cnt3 += 1\n",
    "hours3 = span3/cnt3\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hours = np.array([hours0, hours1, hours2, hours3], dtype=float)\n",
    "data = [datadogdifficulty1.values, w_o, hours]\n",
    "datadogdifficulty = pd.DataFrame(data=data, index=['pd', 'w/o', 'days'], columns=[\"0\", \"1\", \"2\", \"3\"])\n",
    "datadogdifficulty.to_csv(\"datadog-difficulty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 0.6057450167477716),\n",
       " ('2', 0.5139913536663946),\n",
       " ('1', 0.2992613462119449),\n",
       " ('0', 0.09544495776046948)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(datadogdifficulty.T)\n",
    "scaled_features = scaler.transform(datadogdifficulty.T)\n",
    "alt_names = [\"0\", \"1\", \"2\", \"3\"]\n",
    "df_MinMax = pd.DataFrame(data=scaled_features, columns=['pd', 'w/o', 'days'])\n",
    "datadogdifficultyrank = mcdm.rank(df_MinMax.values, alt_names=alt_names,n_method=\"Linear2\", w_method=\"CRITIC\", s_method=\"TOPSIS\")\n",
    "datadogdifficultyrank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
